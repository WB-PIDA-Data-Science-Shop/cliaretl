################################################################################
############### SOME FUNCTIONS FOR DATA PIPELINE MANAGEMENT ####################
################################################################################

utils::globalVariables("variable")

#' Add Metadata Attributes to a Dataset
#'
#' Adds metadata to a `data.frame`, such as the source URL, download date, and any additional information.
#'
#' @param df A `data.frame` object to which metadata will be added.
#' @param source A `character` string indicating the URL or source of the dataset.
#' @param other_info A `character` string containing any additional metadata or descriptive information.
#'
#' @return The input `data.frame` with additional attributes:
#' \describe{
#'   \item{`source`}{The URL or source location of the dataset.}
#'   \item{`other info`}{Any user-supplied contextual information.}
#'   \item{`download_date`}{The date when the data was processed or downloaded.}
#' }
#'
#' @examples
#' df <- data.frame(x = 1:5)
#' df_meta <- add_plmetadata(df,
#'                           source = "https://example.com/data.csv",
#'                           other_info = "Mock dataset for demo")
#' attributes(df_meta)
#'
#' @export
add_plmetadata <- function(df,
                           source,
                           other_info) {
  attr(df, "source") <- source
  attr(df, "other_info") <- other_info
  attr(df, "latest_download") <- Sys.Date()

  return(df)

}


#' Collect metadata from all datasets in the package data folder
#'
#' @param data_path Path to the `data/` folder (default = "data").
#'
#' @return A data frame with metadata for each dataset in the package.
#'
#' @importFrom purrr map_dfr
#' @importFrom rlang %||%
#' @importFrom tibble tibble
#' @export
collect_metadata <- function(data_path = "data") {

  df <-
  list.files(data_path,
             pattern = "\\.rda$",
             full.names = TRUE) |>
    map_dfr(function(file_path) {
      env <- new.env()
      load(file_path, envir = env)

      obj_name <- ls(env)[1]
      obj <- env[[obj_name]]

      tibble::tibble(
        dataset = obj_name,
        source = attr(obj, "source") %||% NA_character_,
        other_info = attr(obj, "other_info") %||% NA_character_,
        latest_download = as.character(attr(obj, "latest_download") %||% NA)
      )
    })

  return(df)

}


#' Flag Mismatched Indicators to Dictionary
#'
#' Identifies variable names in a data frame that are not included in a reference dictionary of valid indicators `db_variables`.
#'
#' @param df A data frame containing extracted indicators along with identifying columns such as `country_code`, `country_name`, and `year`.
#' @param db_variables A data frame called `db_variables` containing a column named `variable` with the list of valid variable names.
#'
#' @return A named list containing a tibble with one column, `variable`, listing the mismatched variables found in `df` but not in `db_variables$variable`.
#' The name of the element in the list is generated by appending `_mismatched_vars` to the original name of the `df` object.
#' @export
flag_mismatched_indicators <- function(df, db_variables) {
  # Load required package
  requireNamespace("tibble", quietly = TRUE)

  # Capture the name of the input data frame
  df_name <- deparse(substitute(df))

  # Exclude identifier variables
  df_vars <- setdiff(names(df), c("country_code", "country_name", "year"))

  # Identify mismatched and missing variable names
  mismatched <- setdiff(df_vars, db_variables$variable)

  # Create tibble of mismatches
  mismatched_df <- tibble::tibble(variable = mismatched)

  # Create named list
  result_name <- paste0(df_name, "_mismatched_vars")
  result <- list()
  result[[result_name]] <- mismatched_df

  return(result)
}


#' Flag Missing Indicators Compared to Dictionary
#'
#' Identifies variables that are in the dictionary (`db_variables`) but missing from the given data frame.
#'
#' @param df A data frame containing extracted indicators along with identifying columns such as `country_code`, `country_name`, and `year`.
#' @param db_variables A data frame containing a column named `variable` with the list of valid variable names, and optionally a `source` column.
#' @param source_type Optional. A character string specifying the source to filter the dictionary (e.g., "WDI").
#'
#' @return A named list containing a tibble with one column, `variable`, listing the variables from `db_variables` that are missing in `df`.
#' The name of the element in the list is generated by appending `_missing_vars` to the original name of the `df` object.
#'
#' @export
flag_missing_indicators <- function(db_variables, df, source_type = NULL) {
  requireNamespace("tibble", quietly = TRUE)
  requireNamespace("dplyr", quietly = TRUE)

  # Filter dictionary if source_type is provided
  dictionary <- if (!is.null(source_type)) {
    db_variables |>
      dplyr::filter(source == source_type) |>
      dplyr::pull(variable)
  }

  df_name <- deparse(substitute(df))
  df_vars <- setdiff(colnames(df), c("country_code", "country_name", "year"))
  missing <- setdiff(dictionary, df_vars)

  missing_df <- tibble::tibble(variable = missing)


  return(missing_df)
}



#' Extract Dataset ID from Indicator Name
#'
#' This function extracts the EFI source (dataset ID) required for an API pull
#' from a given indicator name. It identifies and returns the substring between
#' the first and second occurrences of a specified delimiter character.
#'
#' @param input_id A character string representing the full indicator name.
#' @param splitchar A character string used as the delimiter to split the input. Default is \code{'.'}.
#'
#' @return A character string representing the extracted dataset ID. If the delimiter
#'         is not found twice, the original \code{input_id} is returned.
#'
#' @examples
#' extract_dataset_id("WDI.GDP.PC")
#' extract_dataset_id("IMF.WEO.GDP", splitchar = ".")
#'
#' @export
extract_dataset_id <- function(input_id, splitchar = '.') {
  # Find first occurrence of splitchar
  first_dot_index <- str_locate(input_id, fixed(splitchar))[1]

  if (!is.na(first_dot_index)) {
    # Find second occurrence of splitchar
    remaining_string <- substr(input_id, first_dot_index + 1, nchar(input_id))
    second_dot_pos <- str_locate(remaining_string, fixed(splitchar))[1]

    if (!is.na(second_dot_pos)) {
      second_dot_index <- first_dot_index + second_dot_pos
      return(substr(input_id, 1, second_dot_index - 1))
    }
  }

  return(input_id)
}

#' Extract Data from World Bank API
#'
#' This function retrieves indicator data from either the Data360 or EFI World Bank APIs
#' based on the specified dataset ID and indicator IDs. It handles pagination for large datasets
#' and returns the results as a data frame.
#'
#' @param dataset_id A character string representing the dataset ID to query.
#' @param indicator_ids A character vector of indicator IDs to retrieve.
#' @param source A character string specifying the data source. Must be either \code{"d360"} or \code{"efi"}.
#' @param verbose Logical; if \code{TRUE}, prints detailed request and response information.
#'
#' @return A list with two elements:
#' \describe{
#'   \item{"SUCCESS"}{A data frame containing the retrieved data if the request was successful.}
#'   \item{"ERROR"}{An empty data frame if the request failed.}
#' }
#'
#' @examples
#' \dontrun{
#' Extract_data_from_API("WDI", c("NY.GDP.MKTP.CD"), source = "d360", verbose = TRUE)
#' }
#'
#' @export
Extract_data_from_API <- function(dataset_id, indicator_ids, source, verbose = FALSE) {
  # Base URLs (define these beforehand)
  d360_baseurl <- "https://data360api.worldbank.org/data360/data"
  efi_baseurl <- "https://datacatalogapi.worldbank.org/dexapps/efi/data"

  if (source == 'd360') {
    url <- paste0(d360_baseurl, "?DATABASE_ID=", dataset_id,
                  "&INDICATOR=", paste(indicator_ids, collapse = ","),
                  "&skip=0")
  } else {
    url <- paste0(efi_baseurl, "?datasetId=", dataset_id,
                  "&indicatorIds=", paste(indicator_ids, collapse = ","),
                  "&top=0&skip=0")
  }

  print(url)
  response <- GET(url)
  print(paste("REQUEST STATUS:", status_code(response)))

  if (status_code(response) == 200) {
    data <- content(response, as = "parsed", type = "application/json")
    total_count <- data$count

    if (verbose) {
      print("REQUEST TEXT:")
      print(data)
    }

    all_data <- list()

    if (total_count > 1000) {
      for (i in seq(0, total_count, by = 1000)) {
        if (source == 'd360') {
          fetch_url <- paste0(d360_baseurl, "?DATABASE_ID=", dataset_id,
                              "&INDICATOR=", paste(indicator_ids, collapse = ","),
                              "&skip=", i)
        } else {
          fetch_url <- paste0(efi_baseurl, "?datasetId=", dataset_id,
                              "&indicatorIds=", paste(indicator_ids, collapse = ","),
                              "&top=1000&skip=", i)
        }
        response_chunk <- GET(fetch_url)

        if (status_code(response_chunk) == 200) {
          if (verbose) {
            print("CHUNK RESPONSE TEXT:")
            print(content(response_chunk, as = "text"))
          }
          data_chunk <- content(response_chunk, as = "parsed", type = "application/json")$value
          all_data <- append(all_data, data_chunk)
        } else {
          print(paste("FAILED TO FETCH DATA, status code:", status_code(response_chunk)))
          return(list("ERROR", data.frame()))
        }
      }
    } else {
      data_formatted <- data$value
      all_data <- data_formatted
    }

    # Convert list to dataframe
    APIDataFrame <- bind_rows(all_data)

    if ("count" %in% colnames(APIDataFrame)) {
      APIDataFrame <- select(APIDataFrame, -count)
    }

    return(list("SUCCESS", APIDataFrame))
  } else {
    print(paste("FAILED TO CONNECT TO API, status code:", status_code(response)))
    print(paste("ERROR MSG:", content(response, as = "text")))
    return(list("ERROR", data.frame()))
  }
}




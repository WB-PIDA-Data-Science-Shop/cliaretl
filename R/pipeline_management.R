################################################################################
############### SOME FUNCTIONS FOR DATA PIPELINE MANAGEMENT ####################
################################################################################


#' Add Metadata Attributes to a Dataset
#'
#' Adds metadata to a `data.frame`, such as the source URL, download date, and any additional information.
#'
#' @param df A `data.frame` object to which metadata will be added.
#' @param source A `character` string indicating the URL or source of the dataset.
#' @param other_info A `character` string containing any additional metadata or descriptive information.
#'
#' @return The input `data.frame` with additional attributes:
#' \describe{
#'   \item{`source`}{The URL or source location of the dataset.}
#'   \item{`other info`}{Any user-supplied contextual information.}
#'   \item{`download_date`}{The date when the data was processed or downloaded.}
#' }
#'
#' @examples
#' df <- data.frame(x = 1:5)
#' df_meta <- add_plmetadata(df,
#'                           source = "https://example.com/data.csv",
#'                           other_info = "Mock dataset for demo")
#' attributes(df_meta)
#'
#' @export
add_plmetadata <- function(df,
                           source,
                           other_info) {
  attr(df, "source") <- source
  attr(df, "other_info") <- other_info
  attr(df, "latest_download") <- Sys.Date()

  return(df)

}


#' Collect metadata from all datasets in the package data folder
#'
#' @param data_path Path to the `data/` folder (default = "data").
#'
#' @return A data frame with metadata for each dataset in the package.
#'
#' @importFrom purrr map_dfr
#' @importFrom rlang %||%
#' @importFrom tibble tibble
#' @export
collect_metadata <- function(data_path = "data") {

  df <-
  list.files(data_path,
             pattern = "\\.rda$",
             full.names = TRUE) |>
    map_dfr(function(file_path) {
      env <- new.env()
      load(file_path, envir = env)

      obj_name <- ls(env)[1]
      obj <- env[[obj_name]]

      tibble::tibble(
        dataset = obj_name,
        source = attr(obj, "source") %||% NA_character_,
        other_info = attr(obj, "other_info") %||% NA_character_,
        latest_download = as.character(attr(obj, "latest_download") %||% NA)
      )
    })

  return(df)

}


#' Flag Mismatched Indicators to Dictionary
#'
#' Identifies variable names in a data frame that are not included in a reference dictionary of valid indicators `db_variables`.
#'
#' @param df A data frame containing extracted indicators along with identifying columns such as `country_code`, `country_name`, and `year`.
#' @param dictionary A data frame containing a column named `variable` with the list of valid variable names.
#'
#' @return A named list containing a tibble with one column, `variable`, listing the mismatched variables found in `df` but not in `db_variables$variable`.
#' The name of the element in the list is generated by appending `_mismatched_vars` to the original name of the `df` object.
#' @export
flag_mismatched_indicators <- function(df, dictionary) {
  # Load required package
  requireNamespace("tibble", quietly = TRUE)

  # Capture the name of the input data frame
  df_name <- deparse(substitute(df))

  # Exclude identifier variables
  df_vars <- setdiff(names(df), c("country_code", "country_name", "year"))

  # Identify mismatched and missing variable names
  mismatched <- setdiff(df_vars, dictionary$variable)

  # Create tibble of mismatches
  mismatched_df <- tibble::tibble(variable = mismatched)

  # Create named list
  result_name <- paste0(df_name, "_mismatched_vars")
  result <- list()
  result[[result_name]] <- mismatched_df

  return(result)
}

#' Flag Missing Indicators Compared to Dictionary
#'
#' Identifies variables that are in the dictionary (`db_variables`) but missing from the given data frame.
#' This function offers flexibility by allowing the user to specify the column in `db_variables` that contains
#' the source information, which can be different from the default "source" column.
#'
#' @param dictionary A data frame containing a column named `variable` with the list of valid variable names.
#'   It can also contain a column (specified by `source_colname`) with source information.
#' @param df A data frame containing extracted indicators along with identifying columns such as `country_code`, `country_name`, and `year`.
#' @param source_type Optional. A character string specifying the source to filter the dictionary (e.g., "WDI").
#'   If provided, only variables associated with this source type will be considered from `db_variables`.
#' @param source_colname Optional. A character string specifying the name of the column in `db_variables`
#'   that contains the source information. Defaults to `"source"`. This allows for flexibility if the source
#'   column is named differently (e.g., `"etl_source"`).
#'
#' @return A tibble with one column, `variable`, listing the variables from `db_variables` that are missing in `df`.
#'
#' @export
flag_missing_indicators <- function(dictionary, df, source_type = NULL, source_colname = "source") {
  requireNamespace("tibble", quietly = TRUE)
  requireNamespace("dplyr", quietly = TRUE)

  # Filter dictionary if source_type is provided and source_colname exists
  dictionary <- if (!is.null(source_type) && source_colname %in% colnames(dictionary)) {
    dictionary |>
      dplyr::filter(.data[[source_colname]] == source_type) |>
      dplyr::pull(variable)
  } else {
    # If source_type is not provided or source_colname doesn't exist, use all variables
    dictionary |>
      dplyr::pull(variable)
  }

  df_name <- deparse(substitute(df))
  df_vars <- setdiff(colnames(df), c("country_code", "country_name", "year"))
  missing <- setdiff(dictionary, df_vars)

  missing_df <- tibble::tibble(variable = missing)

  return(missing_df)
}


#' Update Variable Names in db_variables
#'
#' This function efficiently renames multiple entries within a specified column
#' of a provided data frame using a named vector of `new_name = old_name` pairs.
#' It also allows for finding a specific variable's index for manual edits.
#'
#' @param data A data frame containing the target column for renaming.
#' @param rename_map A named character vector (e.g., `c("new_var" = "old_var")`).
#'   If `NULL`, no bulk renaming is applied.
#' @param column_name A character string specifying which column to apply the
#'   renaming to. Defaults to "variable" for backward compatibility.
#' @param find_var_name An optional character string. If provided, the function
#'   will return the row index of this value in the specified column after any renames.
#' @return The modified data frame if `find_var_name` is `NULL`.
#'   If `find_var_name` is provided, returns the numeric row index of the first
#'   match, or `NA` if not found.
#'
#' @examples
#' \dontrun{
#' # Example 1: Apply bulk renames to 'var_name' column
#' rename_map <- c("New Variable A" = "Old Variable A")
#' data_updated <- update_db_variables(data, rename_map = rename_map, column_name = "var_name")
#'
#' # Example 2: Apply bulk renames to 'description' column
#' desc_renames <- c("Updated description" = "Old description")
#' data_updated <- update_db_variables(data, rename_map = desc_renames, column_name = "description")
#' }
#'
#' @export
update_db_variables <- function(data,
                                rename_map = NULL,
                                column_name = "variable",
                                find_var_name = NULL) {
  # Input validation
  if (!is.data.frame(data)) {
    stop("`data` must be a data frame.")
  }

  if (!is.character(column_name) || length(column_name) != 1) {
    stop("`column_name` must be a single character string.")
  }

  if (!column_name %in% names(data)) {
    stop(paste0("The provided data frame must contain a '", column_name, "' column."))
  }

  # Apply bulk renaming if rename_map is provided
  if (!is.null(rename_map)) {
    if (!is.character(rename_map) || is.null(names(rename_map))) {
      stop("`rename_map` must be a named character vector (e.g., c('new' = 'old')).")
    }

    # Apply renaming to the specified column
    match_idx <- match(data[[column_name]], unname(rename_map))
    data[[column_name]][!is.na(match_idx)] <- names(rename_map)[na.omit(match_idx)]

    message(paste0("Renaming applied to the '", column_name, "' column."))
  }

  # Find and return index if find_var_name is provided
  if (!is.null(find_var_name)) {
    if (!is.character(find_var_name) || length(find_var_name) != 1) {
      stop("`find_var_name` must be a single character string.")
    }

    idx <- which(data[[column_name]] == find_var_name)
    if (length(idx) > 0) {
      return(idx[1]) # Return first match
    } else {
      return(NA_integer_) # No match
    }
  }

  return(data) # Return the modified data frame by default
}

#' Extract Dataset ID from Indicator Name
#'
#' This function extracts the EFI source (dataset ID) required for an API pull
#' from a given indicator name. It identifies and returns the substring between
#' the first and second occurrences of a specified delimiter character.
#'
#' @param input_id A character string representing the full indicator name.
#' @param splitchar A character string used as the delimiter to split the input. Default is \code{'.'}.
#'
#' @return A character string representing the extracted dataset ID. If the delimiter
#'         is not found twice, the original \code{input_id} is returned.
#'
#' @examples
#' extract_dataset_id("WDI.GDP.PC")
#' extract_dataset_id("IMF.WEO.GDP", splitchar = ".")
#'
#' @importFrom stringr str_locate fixed
#'
#' @export
#'
extract_dataset_id <- function(input_id, splitchar = '.') {
  # Find first occurrence of splitchar
  first_dot_index <- str_locate(input_id, fixed(splitchar))[1]

  if (!is.na(first_dot_index)) {
    # Find second occurrence of splitchar
    remaining_string <- substr(input_id, first_dot_index + 1, nchar(input_id))
    second_dot_pos <- str_locate(remaining_string, fixed(splitchar))[1]

    if (!is.na(second_dot_pos)) {
      second_dot_index <- first_dot_index + second_dot_pos
      return(substr(input_id, 1, second_dot_index - 1))
    }
  }

  return(input_id)
}

#' Extract Data from World Bank APIs (Data360 or EFI)
#'
#' This function retrieves indicator-level data from either the World Bank Data360 API
#' or the EFI (Enterprise Surveys/EFI Data Catalog) API. It automatically handles pagination
#' for large datasets (over 1000 records) by fetching data in chunks and combining the
#' results into a single data frame.
#'
#' @details
#' - The function constructs a query URL based on the provided `dataset_id`, `indicator_ids`,
#'   and `source` parameters.
#' - For `source = "d360"`, the function queries the Data360 API endpoint.
#' - For `source = "efi"`, it queries the EFI Data Catalog API endpoint.
#' - If the total number of records exceeds 1000, the function iteratively fetches
#'   data in batches of 1000 records until all data is retrieved.
#' - If any API call fails (status code != 200), the function returns an error result.
#'
#' @param dataset_id A character string specifying the dataset ID (e.g., \code{"WDI"}).
#' @param indicator_ids A character vector of indicator IDs to retrieve (e.g., \code{c("NY.GDP.MKTP.CD")}).
#' @param source A character string indicating the API source.
#'        Must be one of \code{"d360"} or \code{"efi"}.
#' @param verbose Logical; if \code{TRUE}, prints detailed request information
#'        (including URLs and raw responses for each request).
#'
#' @return A list of length two:
#' \describe{
#'   \item{\code{"SUCCESS"}}{A data frame containing all requested indicator data.}
#'   \item{\code{"ERROR"}}{An empty data frame if any API request fails.}
#' }
#'
#' @section Error Handling:
#' - If the initial request fails, an "ERROR" result is returned along with an empty data frame.
#' - If a chunked request (pagination) fails, the function stops and returns "ERROR".
#'
#' @examples
#' \dontrun{
#' # Example: Retrieve GDP data from the WDI dataset using the Data360 API
#' result <- Extract_data_from_API(
#'   dataset_id = "WDI",
#'   indicator_ids = c("NY.GDP.MKTP.CD"),
#'   source = "d360",
#'   verbose = TRUE
#' )
#'
#' if (result[[1]] == "SUCCESS") {
#'   head(result[[2]])
#' }
#' }
#'
#' @seealso
#' \itemize{
#'   \item{\code{\link[httr]{GET}} for HTTP GET requests.}
#'   \item{\code{\link[dplyr]{bind_rows}} for combining the paginated results.}
#' }
#'
#' @import httr
#' @export
#'
extract_data_from_api <- function(dataset_id,
                                  indicator_ids,
                                  source,
                                  verbose = FALSE) {

  # Base URLs (define these beforehand)
  d360_baseurl <- "https://data360api.worldbank.org/data360/data"
  efi_baseurl <- "https://datacatalogapi.worldbank.org/dexapps/efi/data"

  if (source == 'd360') {
    url <- paste0(d360_baseurl, "?DATABASE_ID=", dataset_id,
                  "&INDICATOR=", paste(indicator_ids, collapse = ","),
                  "&skip=0")
  } else {
    url <- paste0(efi_baseurl, "?datasetId=", dataset_id,
                  "&indicatorIds=", paste(indicator_ids, collapse = ","),
                  "&top=0&skip=0")
  }

  print(url)
  response <- httr::GET(url)
  print(paste("REQUEST STATUS:", httr::status_code(response)))

  if (httr::status_code(response) == 200) {
    data <- httr::content(response, as = "parsed", type = "application/json")
    total_count <- data$count

    if (verbose) {
      print("REQUEST TEXT:")
      print(data)
    }

    all_data <- list()

    if (total_count > 1000) {
      for (i in seq(0, total_count, by = 1000)) {
        if (source == 'd360') {
          fetch_url <- paste0(d360_baseurl, "?DATABASE_ID=", dataset_id,
                              "&INDICATOR=", paste(indicator_ids, collapse = ","),
                              "&skip=", i)
        } else {
          fetch_url <- paste0(efi_baseurl, "?datasetId=", dataset_id,
                              "&indicatorIds=", paste(indicator_ids, collapse = ","),
                              "&top=1000&skip=", i)
        }
        response_chunk <- httr::GET(fetch_url)

        if (httr::status_code(response_chunk) == 200) {
          if (verbose) {
            print("CHUNK RESPONSE TEXT:")
            print(httr::content(response_chunk, as = "text"))
          }
          data_chunk <- httr::content(response_chunk, as = "parsed", type = "application/json")$value
          all_data <- append(all_data, data_chunk)
        } else {
          print(paste("FAILED TO FETCH DATA, status code:", httr::status_code(response_chunk)))
          return(list("ERROR", data.frame()))
        }
      }
    } else {
      data_formatted <- data$value
      all_data <- data_formatted
    }

    # Convert list to dataframe
    APIDataFrame <- dplyr::bind_rows(all_data)

    if ("count" %in% colnames(APIDataFrame)) {
      APIDataFrame <- dplyr::select(APIDataFrame, -count)
    }

    return(list("SUCCESS", APIDataFrame))
  } else {
    print(paste("FAILED TO CONNECT TO API, status code:", httr::status_code(response)))
    print(paste("ERROR MSG:", httr::content(response, as = "text")))
    return(list("ERROR", data.frame()))
  }
}

#' Scale Values to [0, 1] Range
#'
#' This function rescales a numeric vector to the zero to unit range using
#' min-max normalization. Missing values (`NA`) are ignored
#' when computing the minimum and maximum.
#'
#' @param x A numeric vector to be scaled.
#'
#' @return A numeric vector where all non-missing values are
#' rescaled to the range [0, 1]. If all elements of `x` are `NA`,
#' the result will be `NA`.
#'
#' @examples
#' scale_values(c(1, 2, 3, 4, 5))
#' # Returns: 0.00 0.25 0.50 0.75 1.00
#'
#' scale_values(c(10, 20, NA, 30))
#' # Returns: 0.00 0.50   NA  1.00
#'
#' @export
scale_values <- function(x){
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

<<<<<<< HEAD
=======

#' Compare Variable Values Between CLIAR Pipelines Using Pointblank
#'
#' @param old_df Data frame from the previous pipeline (gold standard)
#' @param new_df Data frame from the new pipeline
#'
#' @return A summary tibble and a printed pointblank agent
#' @export
#'
#' @import dplyr tidyr pointblank
#' @importFrom stats median na.omit
#'
#' @examples
#' # Create example old and new datasets
#' set.seed(123)
#' old_df <- data.frame(
#'   country_code = rep(c("USA", "KEN", "NGA"), each = 2),
#'   year = rep(2020:2021, 3),
#'   gdp = c(50000, 52000, 1800, 1900, 2400, 2600),
#'   population = c(330e6, 331e6, 53e6, 54e6, 206e6, 208e6)
#' )
#'
#' new_df <- data.frame(
#'   country_code = rep(c("USA", "KEN", "NGA"), each = 2),
#'   year = rep(2020:2021, 3),
#'   gdp = c(50500, 52200, 1850, 1950, 2450, 2650),  # small changes
#'   population = c(330e6, 331e6, 53e6, 54.1e6, 206e6, 208.5e6)  # small changes
#' )
#'
#' # Run quality check
#' results <- qualitycheck_plvalue(old_df, new_df)
#'
#' # View summary
#' results$summary
#'
#' # Export a single agent report (optional)
#' # pointblank::export_report(results$agents[[1]], filename = "example_qc_report.html")
#'
qualitycheck_plvalue <- function(old_df,
                                 new_df) {

  common_vars <- intersect(names(old_df), names(new_df))

  check_list <-
    lapply(common_vars,
           function(var) {

            old_df <-
              old_df |>
              dplyr::select(country_code, year, !!sym(var)) |>
              na.omit()

            country_list <- unique(old_df[["country_code"]])
            year_list <- unique(old_df[["year"]])


            new_df <-
              new_df |>
              dplyr::select(country_code, year, !!sym(var)) |>
              dplyr::filter(country_code %in% country_list &
                              year %in% year_list)

            old_col <- old_df[[var]]
            new_col <- new_df[[var]]

            # Ensure comparable numeric values
            if (is.numeric(old_col) && is.numeric(new_col)) {
              tibble(
                variable = var,
                old_class = class(old_col)[1],
                new_class = class(new_col)[1],
                type_equal = class(old_col)[1] != class(new_col)[1],
                old_min = min(old_col, na.rm = TRUE),
                old_max = max(old_col, na.rm = TRUE),
                new_min = min(new_col, na.rm = TRUE),
                new_max = max(new_col, na.rm = TRUE),
                old_mean = mean(old_col, na.rm = TRUE),
                new_mean = mean(new_col, na.rm = TRUE),
                old_median = median(old_col, na.rm = TRUE),
                new_median = median(new_col, na.rm = TRUE),
                old_n_na = sum(is.na(old_col)),
                new_n_na = sum(is.na(new_col)),
                range_equal = (min(old_col, na.rm = TRUE) != min(new_col, na.rm = TRUE)) |
                  (max(old_col, na.rm = TRUE) != max(new_col, na.rm = TRUE)),
                mean_equal = !isTRUE(all.equal(mean(old_col, na.rm = TRUE), mean(new_col, na.rm = TRUE))),
                median_equal = !isTRUE(all.equal(median(old_col, na.rm = TRUE), median(new_col, na.rm = TRUE))),
                missingness_equal = sum(is.na(old_col)) != sum(is.na(new_col))
              )
            } else {
              tibble(
                variable = var,
                old_class = class(old_col)[1],
                new_class = class(new_col)[1],
                type_equal = class(old_col)[1] != class(new_col)[1],
                old_min = NA_real_,
                old_max = NA_real_,
                new_min = NA_real_,
                new_max = NA_real_,
                old_mean = NA_real_,
                new_mean = NA_real_,
                old_median = NA_real_,
                new_median = NA_real_,
                old_n_na = sum(is.na(old_col)),
                new_n_na = sum(is.na(new_col)),
                range_equal = NA,
                mean_equal = NA,
                median_equal = NA,
                missingness_equal = sum(is.na(old_col)) != sum(is.na(new_col))
              )
            }
  })

  comparison_tbl <- bind_rows(check_list)

  # Pointblank summary agent (optional)
  agent <-
    create_agent(tbl = comparison_tbl) %>%
    col_vals_not_null(vars(variable)) %>%
    col_vals_equal(vars(type_equal), value = FALSE, brief = "Type changed") %>%
    col_vals_equal(vars(range_equal), value = FALSE, brief = "Range changed") %>%
    col_vals_equal(vars(mean_equal), value = FALSE, brief = "Mean changed") %>%
    col_vals_equal(vars(median_equal), value = FALSE, brief = "Median changed") %>%
    col_vals_equal(vars(missingness_equal), value = FALSE, brief = "Missingness changed")

  agent <- interrogate(agent)

  print(agent)

  return(comparison_tbl)

}




#' Compare CLIAR Pipeline Indicator Values Across Versions
#'
#' This function compares the indicator values between an old (published) and a new (updated)
#' version of a CLIAR pipeline dataset. It identifies changes in values for matching country-year-indicator
#' combinations, as well as any new data entries (e.g. new country-year combinations).
#' A [pointblank](https://rich-iannone.github.io/pointblank/) agent report is generated to summarize changes.
#'
#' @param old_df A data frame representing the old CLIAR dataset (e.g., already published).
#' Must include `country_code`, `year`, and indicator columns.
#'
#' @param new_df A data frame representing the new CLIAR dataset (e.g., updated data for new release).
#' Must include `country_code`, `year`, and indicator columns.
#'
#' @return A data frame (tibble) showing rows where indicator values have changed, mismatched, or are newly introduced.
#' Also prints a `pointblank` interrogation report to the console.
#'
#' @details
#' - Only compares indicators common to both `old_df` and `new_df`.
#' - Assumes both data frames are in wide format, with indicator variables as columns.
#' - Indicator values are compared for all shared `(country_code, year, indicator)` triples.
#' - Differences due to `NA` mismatches are also reported.
#' - New `country_code-year-indicator` combinations in the updated pipeline are flagged.
#'
#' @export
#'
#' @import dplyr tidyr pointblank rlang
compare_pipeline_indicators <- function(old_df, new_df) {

  # Identify common columns
  common_indicators <- setdiff(intersect(names(old_df), names(new_df)),
                               c("country_code", "year"))

  # Reshape both to long format
  old_long <-
    old_df %>%
    select(country_code, year, all_of(common_indicators)) |>
    pivot_longer(cols = all_of(common_indicators),
                 names_to = "indicator", values_to = "old_value")

  new_long <-
    new_df %>%
    select(country_code, year, all_of(common_indicators)) |>
    pivot_longer(cols = all_of(common_indicators),
                 names_to = "indicator", values_to = "new_value")

  # Full outer join to keep all combinations
  compare_df <-
    merge(old_long,
          new_long,
          by = c("country_code", "year", "indicator"),
          all = TRUE) |>
    mutate(value_equal = old_value == new_value,
           is_update = is.na(old_value) & !is.na(new_value)) |>
    mutate(over_1pct_change =
             case_when(!is.na(old_value) & !is.na(new_value) & old_value != 0 ~
                        abs((new_value - old_value) / old_value) > 0.01,
        TRUE ~ NA))

  # Create pointblank agent
  agent <-
    compare_df %>%
    create_agent() %>%
    col_vals_equal(vars(value_equal), value = TRUE,
                   preconditions = ~ . %>% filter(!is.na(old_value) & !is.na(new_value)),
                   brief = "Check if indicator values changed") |>
    col_vals_not_equal(over_1pct_change, value = TRUE,
                       preconditions = ~ . %>% filter(!is.na(over_1pct_change)),
                       brief = "Check if changed values are more than 1% abs difference") |>
    col_vals_equal(vars(is_update), value = FALSE,
                   preconditions = ~ . %>% filter(!is.na(new_value)),
                   brief = "Check for new data not in previous pipeline") |>
    interrogate()

  # Print the agent report
  print(agent)

  # Rows that changed or are newly added
  diff_df <-
    compare_df |>
    filter(is_update | !value_equal | is.na(value_equal)) |>
    filter(!if_all(c(old_value, new_value, value_equal), is.na))

  # Message if no updates or changes
  if (nrow(diff_df) == 0) {
    message("No indicator updates or changes detected between versions.")
  }

  return(list(agent = agent, difference_table = diff_df))
}


#' @keywords internal
#' @noRd
#'
#' @importFrom rmarkdown render
#'
#' This quick function will generate the comparison report using the
#' compare_pipeline_indicators() function within a markdown file stored
#' in a temporary location.
#'
generate_pipeline_comparison_report <- function() {
  tmp_file <- tempfile(fileext = ".html")

  rmarkdown::render(
    input = "inst/qcheck/indicators_compare_pipeline.Rmd",
    output_format = "html_document",
    output_file = tmp_file
  )

  message("Report generated at: ", tmp_file)
  return(tmp_file)
}















>>>>>>> main
